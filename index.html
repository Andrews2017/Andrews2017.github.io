<!-- Page adopted from https://github.com/adjidieng/adjidieng.github.io and https://github.com/jonbarron/website -->

<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    a {
      color: #1772d0;
      text-decoration:none;
    }

    em {
      color: #1772d0;
    }

    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }

    td,th,tr,p,a {
      font-family:  'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 17px;
      font-weight: 300;
    }

    body { 
    	margin:5px 0; 
    	padding:0; 
    	font-size: 100%;
    	font-family: "PT Serif","Georgia","Helvetica Neue",Arial,sans-serif; 
    	color:#FFF;  
    	background-color:#eee;
    	line-height: 1.4em; 
    	/*background : #E4E4E4 url(bg.gif) repeat-x;*/
     	/*background: #E4E4E4 url(bg_light.gif) repeat-x; */
    	background: #FFFFFF url(bc-website-color.gif) repeat-x;
    }
    p { 
    	margin: 0 0 5px 0; 
    	padding: 0; 
    	color: #404241; 
    	background: inherit;
    	font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 95%;
      font-weight: 400;
    }

    hr {
      border: 0;
      height: 1px;
      color: #eee;
      background-color: #eee;
    }

    a { 
    	background: inherit; 
    	text-decoration:none;
    	font-size:95%;
      color: #191970;

    }

    a:hover { 
    	background: inherit;
    	text-decoration: none;

    }

    h1 { 
    	padding:0; 
    	margin:0; 
    	color: #434A55; 
    	background: inherit;
    	font-family: serif; 
    	/*font-size: 22px;*/
    	/*letter-spacing: 0px;*/
    }

    h1 a {
    	color: #191970; 
    	background: inherit;
    }

    h2 { 
    	background-color: inherit; 
    	color:#191970; 
    	margin: 10px 20px 10px 0px; 
    	padding:15px 0px 0 0px; 
    	font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 18px;
      font-weight: 500;

    }

    h2 a { 
    	/*background-color:#08152E;*/ 
    	/*background-color:#E4E4E4;*/
    	background-color:#FFFFFF;
    }

    ul { 	margin: 0 0 20px 0; 
    	padding : 0; 
    	list-style : none; 
      color: #555;
    }
    	
    li { 
    	float: left;
    	font-weight: bold;
    	margin: 10px 0 8px 0;
    	padding: 0 0 0 5px;
    	font-size: 95%%;
    	font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    	font-weight: 400;
      color: #404241;

    }

    li a { 
      font-size: 95%;
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-weight: 400;
      color: #191970; }
    li a:hover {text-decoration: none; 
      background: inherit url(select.gif) no-repeat center top;padding: 2px 4px;
    	background-position: 100% 100%;
      color: #DBBC58;
      padding: 4px 8px; 
      background-color:#191970; 
      border-radius: 25px;
      display: run-in;
    }

    strong {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 15px;
      color: #191970;
    }

    heading {
      font-family:  'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 23px;
      color: #191970;
    }

    papertitle {
      font-family:  'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 17px;
      font-weight: 700
    }

    name {
      font-family:  "PT Serif","Georgia","Helvetica Neue",Arial,sans-serif; 
      font-size: 35px;
      font-weight: bold;
    }
    
    span.highlight {
      background-color: #ffffd0;
    }

    .some_list { 
    	font-size: 93%;
    	font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    	font-weight: 400;
    	/*float: none;*/
    	list-style-type: circle;
    	padding : 0px; 
    	margin: 0 0 10px 30px; 
      }
  </style>
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="Images/profile_pic.png">
  <title>Rubungo Andre Niyongabo </title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Roboto:300,400,500,700,900,100italic,100,300,300italic,400italic,500italic,900italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <table width="70%" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
          <p>
            <name>Rubungo Andre Niyongabo</name>
          </p>
          <p>
            <img src="Images/profile_pic.png" width="30%">
          </p>
          <p>
            <a href=" ">CV</a> &nbsp/&nbsp
            <a href="https://scholar.google.com/citations?user=5qnTWQEAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
            <a href="https://www.linkedin.com/in/rubungo-andre-niyongabo-851370168/"> LinkedIn </a> &nbsp/&nbsp
            <a href="https://github.com/Andrews2017">Github</a> &nbsp/&nbsp
            <a href="https://twitter.com/andre_niyongabo">Twitter</a>  &nbsp/&nbsp
            <a> Email:</a>  niyongabo dot rubungo dot andre at upc dot edu 
          </p>
        </td>
      </tr>
      </table> -->
  
      <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <p>I am a Research Assistant in the department of <a href="https://www.cs.upc.edu/">Computer Science</a>
          at <a href="https://www.upc.edu/en">Polytechnic University of Catalonia (UPC)</a> where I am jointly working with <a href="https://costa-jussa.com/">Prof. Marta R. Costa-jussà</a>
          and  <a href="https://www.talp.upc.edu/staff-detail-page-2/61/Carlos-Escolano%20Peinado">Carlos Escolano</a> on <a href="https://lunar.cs.upc.edu/">LUNAR</a> project. In my research, I work on improving Neural Machine Translation systems for Extremely Low Resource Languages, especially African languages. My work is funded by the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme. 
          </p>

          <p> &nbsp </p>
          <p>
           Prior to joining UPC I did my masters and undergraduate in Computer Science in China at <a href="https://en.uestc.edu.cn/">University of Electronic Science and Technology of China (UESTC)</a>. During my masters, I did internships at <a href="https://www.huawei.com/en/corporate-information/research-development">Huawei</a> and <a href="https://online.iwhalecloud.com/">WhaleCloud</a> as an Artificial Intelligence (AI) Engineer. While at UESTC, I have received several awards including <a href="Awards/chinese_government_award_2021.pdf">Chinese Government Outstanding International Masters Student Award</a>, <a href="Awards/uestc_outstanding_masters_stud_award_2021.pdf">UESTC Outstanding Masters Student Award</a>, and <a href="Awards/uestc_undergraduate_outstanding_stud_award.pdf">UESTC Outstanding Undergraduate Student Award</a>.
          </p>
        </td> 
      </tr>
      </table> -->

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Rubungo Andre Niyongabo</name>
              </p>
              <p>I am a Research Assistant in the department of <a href="https://www.cs.upc.edu/">Computer Science</a>
              at <a href="https://www.upc.edu/en">Polytechnic University of Catalonia (UPC)</a> where I am jointly working with <a href="https://costa-jussa.com/">Prof. Marta R. Costa-jussà</a>
              and  <a href="https://www.talp.upc.edu/staff-detail-page-2/61/Carlos-Escolano%20Peinado">Carlos Escolano</a> on <a href="https://lunar.cs.upc.edu/">LUNAR</a> project.
              </p>
              <br> 
              <p>In my research, I work on improving Neural Machine Translation systems for Extremely Low Resource Languages, especially African languages. My work is funded by the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme. 
              </p>
              <br>
              <p>
              Prior to joining UPC, I did my masters and undergraduate in Computer Science in China at <a href="https://en.uestc.edu.cn/">University of Electronic Science and Technology of China (UESTC)</a>. During my masters, I did internships at <a href="https://www.huawei.com/en/corporate-information/research-development">Huawei</a> and <a href="https://online.iwhalecloud.com/">WhaleCloud</a> as an Artificial Intelligence (AI) Engineer. While at UESTC, I have received several awards including <a href="Awards/chinese_government_award_2021.pdf">China Government Outstanding International Masters Student Award</a>, <a href="Awards/uestc_outstanding_masters_stud_award_2021.pdf">UESTC Outstanding Masters Student Award</a>, and <a href="Awards/uestc_undergraduate_outstanding_stud_award.pdf">UESTC Outstanding Undergraduate Student Award</a>.
              </p>
              <br>
              <p style="text-align:center">
                <a href="CV/CV_Andre_part_1.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=5qnTWQEAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/rubungo-andre-niyongabo-851370168/"> LinkedIn </a> &nbsp/&nbsp
                <a href="https://github.com/Andrews2017">Github</a> &nbsp/&nbsp
                <a href="https://twitter.com/andre_niyongabo">Twitter</a>  &nbsp/&nbsp
                <a> Email:</a>  niyongabo dot rubungo dot andre at upc dot edu 
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="Images/profile_pic_circula.png"><img style="width:100%;max-width:100%" alt="profile photo" src="Images/profile_pic_circula.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody>
      </table>
 
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>News</heading>
          <ul style="list-style-type:circle">
            <li class="some_list"> Feb 2022: Our paper titled "KinyaBERT: a Morphology-aware Kinyarwanda Language Model" has been accepted at <a href="https://www.2022.aclweb.org/">ACL 2022 main conference</a>.</li>
            <li class="some_list"> Nov 2021: Started reviewing for <a href="https://iclr.cc/">ICLR 2022</a>.</li>
            <li class="some_list">Oct 2021: Starting a Research Assistant position in Computer Science departemet at <a href="https://www.upc.edu/en">UPC</a></li>
            <li class="some_list"> Jul 2021: Starting a Research and Development Internship at <a href="https://www.huawei.com/en/corporate-information/research-development">Huawei</a>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;</li>
            <li class="some_list"> Jul 2021: Received a master's degree from <a href="https://en.uestc.edu.cn/">UESTC</a></li>
            <li class="some_list"> Feb 2021: Received <a href="Awards/chinese_government_award_2021.pdf">China Government Outstanding International Masters Student Award</a>.</li>
            <li class="some_list"> Dec 2020: Received <a href="Awards/uestc_outstanding_masters_stud_award_2021.pdf">UESTC Outstanding Masters Student Award</a>.</li>
            <li class="some_list">Oct 2020: Our paper titled "KINNEWS and KIRNEWS: Benchmarking Cross-Lingual Text Classification for Kinyarwanda and Kirundi" has been accepted at <a href="https://coling2020.org/">COLING 2020</a> </li>
            <li class="some_list"> Sep 2020: Our paper titled "Participatory Research for Low-resourced Machine Translation: A Case Study in African Languages" has been accepted at <a href="https://2020.emnlp.org/">EMNLP-Findings 2020</a> .</li>
            <li class="some_list">Feb 2020: Our paper titled "Weakly-supervised Character-level Convolutional Neural Networks for Text Classification" accepted been at <a href="https://www.hrm-bildung.de/flins2020/">FLINS 2020</a>.</li>
            <li class="some_list">Sep 2019: Awarded China Government Full Scholarship for Masters.&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;</li>
            <li class="some_list">Awarded 2018 UESTC Outstanding Student Award.</li>
          </ul>         
        </td>
      </tr>
      </table>

      <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading> Selected Invited Talks </heading>
          <ul  style="list-style-type:circle">
            <li class="some_list"><a href="https://www.cs.cmu.edu/calendar/tue-2019-11-26-1030/machine-learningduolingo-seminar">Carnegie Mellon University Machine Learning Seminar</a>, Pittsburgh, PA, November 2019 </li>
            <li class="some_list"> Add more here...</li>  
          </ul>         
        </td>
      </tr>
      </table> -->

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Research</heading>
          <p> My main goal as a Natural Language Processing (NLP) researcher is to increase the representation of low resource languages, especially African languages in an NLP community. My previous works range from the creation and curation of new datasets, machine translation, text classification, text summarization, sentiment analysis, named-entity recognition, and common sense reasoning. 
          </p>
        </td>
      </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="25">
      <tr>
        <td width="25%">
          <img src='Images/kinyabert.JPG' width="280" height="250">
        </td>
        <td valign="top" width="75%">
          <p>
            <a href="https://openreview.net/forum?id=AunN5vQYjsB">
              <papertitle>KinyaBERT: A Morphology-aware Kinyarwanda Language Model</papertitle>
            </a>
            <br>
            <a href="https://www.linkedin.com/antoine-nzeyimana-23b302112">Antoine Nzeyimana</a>,
            <strong>Rubungo Andre Niyongabo</strong>
            <br>Accepted at ACL 2022</em>
            <br>
            <a href="https://openreview.net/forum?id=AunN5vQYjsB">Paper</a>
          </p>
          <p>Pre-trained language models such as BERT have been successful at tackling many natural language processing tasks. However, the unsupervised sub-word tokenization methods commonly used in these models (e.g., byte-pair encoding - BPE) are sub-optimal at handling morphologically rich languages. Even given a morphological analyzer, naive sequencing of morphemes into a standard BERT architecture is inefficient at capturing morphological compositionality and expressing word-relative syntactic regularities. We address these challenges by proposing a simple two-tier BERT architecture that leverages a morphological analyzer and explicitly represents morphological compositionality. Despite the success of BERT, most of its evaluations have been conducted on high-resource languages, obscuring its applicability on low-resource languages. We evaluate our proposed method on the low-resource morphologically rich Kinyarwanda language, naming the proposed model architecture KinyaBERT. A robust set of experimental results reveal that KinyaBERT outperforms solid baselines by 2% F1 score on a named entity recognition task and by 4.3% average score of a machine-translated GLUE benchmark. KinyaBERT fine-tuning has better convergence and achieves more robust results on multiple tasks even in the presence of translation noise.</p>
        </td>
      </tr>
      <tr>
        <td width="25%">
          <img src='Images/gem_1.JPG' width="280" height="250">
        </td>
        <td valign="top" width="75%">
          <p>
            <a href="Papers/GEM_Benchmark_1.pdf">
              <papertitle>The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics</papertitle>
            </a>
            <br>
            <a href="https://sebastiangehrmann.com/">Sebastian Gehrmann</a>,
            <a href="https://scholar.google.com/citations?user=uBZIR8sAAAAJ&hl=en">Tosin Adewumi</a>,
            <span>et al. including</span>
            <strong>Rubungo Andre Niyongabo</strong>
            <br>
            <em> In the Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021), pages 96–120</em>
            <br>
            <a href="https://aclanthology.org/2021.gem-1.10/">Paper</a>
            /
            <a href="https://gem-benchmark.com/">Website</a>
            / 
            <a href="https://gem-benchmark.com/team">Team</a>
          </p>
          <p>GEM is a benchmark environment for Natural Language Generation with a focus on its Evaluation, both through human annotations and automated Metrics. It aims to measure NLG progress across many NLG tasks across languages, audit data and models and present results via data cards and model robustness reports, and develop standards for evaluation of generated text using both automated and human metrics.</p>
        </td>
      </tr>
      <tr>
        <td width="25%">
          <img src='Images/mpt.png' width="280" height="250">
        </td>
        <td valign="top" width="75%">
          <p>
            <a href="https://dl.acm.org/doi/abs/10.1145/3457682.3457759">
              <papertitle>Multi-Perspective Reasoning Transformers</papertitle>
            </a>
            <br>
            <a href="https://www.linkedin.com/in/dagisky/">Dagmawi Moges</a>,
            <strong>Rubungo Andre Niyongabo</strong>,
            <a href="https://en.uestc.edu.cn/info/1074/2124.htm">Hong Qu</a>
            <br>
            <em>In 2021 13th International Conference on Machine Learning and Computing (ICMLC 2021)</em>
            <br>
            <a href="https://dl.acm.org/doi/abs/10.1145/3457682.3457759">Paper</a>
          </p>
          <p>Machine Reading Comprehension is defined as the ability of machines to read and understand unstructured text and answer questions about it. It is considered as a challenging task with wide range of enterprise applications. Wide range of natural language understanding and reasoning tasks are found embedded within machine reading comprehension datasets. This requires effective models with robust relational reasoning capabilities to answer complex questions. Reasoning in natural language is a long-term machine-learning goal and is critically needed for building intelligent agents. However, most papers heavily depend on underlying language modeling and thus pay little to no attention on creating effective reasoning models. This paper proposes a modified transformer architecture that effectively combines soft and hard attention to create multi-perspective reasoning model capable of tackling wide range of reasoning tasks. An attention mechanism that highlights the relational significance of input signals is considered as well. The result from this study shows performance gain as compared to its counterpart the transformer network on bAbI dataset, a natural language reasoning tasks.</p>
        </td>
      </tr>
      <tr>
        <td width="25%">
          <img src='Images/masakhaner.JPG' width="280" height="250">
        </td>
        <td valign="top" width="75%">
          <p>
            <a href="https://doi.org/10.1162/tacl_a_00416">
              <papertitle>MasakhaNER: Named Entity Recognition for African Languages.</papertitle>
            </a>
            <br>
            <a href="https://dadelani.github.io/">David I. Adelani</a>,
            <a href="https://www.jabbott.io/">Jade Abbott</a>,
            <span>et al. including</span>
            <strong>Rubungo Andre Niyongabo</strong>
            <br>
            <em> Transactions of the Association for Computational Linguistics (2021).</em>
            <br>
            <a href="https://doi.org/10.1162/tacl_a_00416">Paper</a>
            /
            <a href="https://www.youtube.com/watch?v=h-X6gMz-fjk">Video</a>
            / 
            <a href="https://github.com/masakhane-io/masakhane-ner">Code</a>
          </p>
          <p>We take a step towards addressing the under- representation of the African continent in NLP research by bringing together different stakeholders to create the first large, publicly available, high-quality dataset for named entity recognition (NER) in ten African languages. We detail the characteristics of these languages to help researchers and practitioners better understand the challenges they pose for NER tasks. We analyze our datasets and conduct an extensive empirical evaluation of state- of-the-art methods across both supervised and transfer learning settings.</p>
        </td>
      </tr>
      <tr>
        <td width="25%">
          <img src='Images/quality_at_glance.JPG' width="280" height="250">
        </td>
        <td valign="top" width="75%">
          <p>
            <a href="https://doi.org/10.1162/tacl_a_00447">
              <papertitle>Quality at a Glance: An Audit of Web-Crawled Multilingual Datasets.</papertitle>
            </a>
            <br>
            <a href="https://scholar.google.com/citations?user=myh9l2AAAAAJ&hl=en">Isaac Caswel</a>,
            <a href="https://juliakreutzer.github.io/">Julia Kreutzer</a>,
            <span>et al. including</span>
            <strong>Rubungo Andre Niyongabo</strong>
            <br>
            <em> Transactions of the Association for Computational Linguistics (2021).</em>
            <br>
            <a href="https://doi.org/10.1162/tacl_a_00447">Paper</a>
<!--             /
            <a href="">Video</a>
            / 
            <a href="">Poster</a> -->
          </p>
          <p>With the success of large-scale pre-training and multilingual modeling in Natural Language Processing (NLP), recent years have seen a proliferation of large, Web-mined text datasets covering hundreds of languages. We manually audit the quality of 205 language-specific corpora released with five major public datasets (CCAligned, ParaCrawl, WikiMatrix, OSCAR, mC4). Lower-resource corpora have systematic issues: At least 15 corpora have no usable text, and a significant fraction contains less than 50% sentences of acceptable quality. In addition, many are mislabeled or use nonstandard/ambiguous language codes. We demonstrate that these issues are easy to detect even for non-proficient speakers, and supplement the human audit with automatic analyses. Finally, we recommend techniques to evaluate and improve multilingual corpora and discuss potential risks that come with low-quality data releases.</p>
        </td>
      </tr>
      <tr>
        <td width="25%">
          <img src='Images/kinnews_kirnews.JPG' width="280" height="250">
        </td>
        <td valign="top" width="75%">
          <p>
            <a href="https://www.aclweb.org/anthology/2020.coling-main.480/">
              <papertitle>KINNEWS and KIRNEWS: Benchmarking Cross-Lingual Text Classification for Kinyarwanda and Kirundi</papertitle>
            </a>
            <br>
            <strong>Rubungo Andre Niyongabo</strong>,
            <a href="https://en.uestc.edu.cn/info/1074/2124.htm">Hong Qu</a>,
            <a href="https://juliakreutzer.github.io/">Julia Kreutzer</a>,
            <a href="">Li Huang</a>
            <br>
            <em> COLING 2020.</em>
            <br>
            <a href="Papers/kinnews_kirnews.pdf">Paper</a>
            /
            <a href="https://github.com/Andrews2017/KINNEWS-and-KIRNEWS-Corpus">Code</a>
          </p>
          <p>Recent progress in text classification has been focused on high-resource languages such as English and Chinese. For low-resource languages, amongst them most African languages, the lack of well-annotated data and effective preprocessing, is hindering the progress and the transfer of successful methods. In this paper, we introduce two news datasets (KINNEWS and IRNEWS) for multi-class classification of news articles in Kinyarwanda and Kirundi, two low-resource African languages. The two languages are mutually intelligible, but while Kinyarwanda has been studied in Natural Language Processing (NLP) to some extent, this work constitutes the first study on Kirundi. Along with the datasets, we provide statistics, guidelines for preprocessing, and monolingual and cross-lingual baseline models. Our experiments show that training embeddings on the relatively higher-resourced Kinyarwanda yields successful cross-lingual transfer to Kirundi. In addition, the design of the created datasets allows for a wider use in NLP beyond text classification in future studies, such as representation learning, cross-lingual learning with more distant languages, or as base for new annotations for tasks such as parsing, POS tagging, and NER.</p>
        </td>
      </tr>
      <tr>
        <td width="25%">
          <img src='Images/participatory_research.JPG' width="280" height="250">
        </td>
        <td valign="top" width="75%">
          <p>
            <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.195/">
              <papertitle>Participatory Research for Low-resourced Machine Translation: A Case Study in African Languages</papertitle>
            </a>
            <br>
            <span>∀</span>,
            <a href="">Wilhelmina Nekoto</a>,
            <a href="https://www.vima.co.za/">Vukosi Marivate</a>,
            <span>et al. including</span>
            <strong>Rubungo Andre Niyongabo</strong>
            <br>
            <em> (EMNLP-Findings 2020. ∀:Equal contribution)</em>
            <br>
            <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.195">Paper</a>
            /
            <a href="https://www.youtube.com/watch?v=Xbc_g_OknqA">Video</a>
            / 
            <a href="https://github.com/masakhane-io/masakhane-mt">Code</a>
          </p>
          <p>Research in NLP lacks geographic diversity, and the question of how NLP can be scaled to low-resourced languages has not yet been adequately solved. ‘Low-resourced’-ness is a complex problem going beyond data availability and reflects systemic problems in society. In this paper, we focus on the task of Machine Translation (MT), that plays a crucial role for information accessibility and communication worldwide. Despite immense improvements in MT over the past decade, MT is centered around a few high-resourced languages. As MT researchers cannot solve the problem of low-resourcedness alone, we propose participatory research as a means to involve all necessary agents required in the MT development process. We demonstrate the feasibility and scalability of participatory research with a case study on MT for African languages. Its implementation leads to a collection of novel translation datasets, MT benchmarks for over 30 languages, with human evaluations for a third of them, and enables participants without formal training to make a unique scientific contribution.</p>
        </td>
      </tr>
      <tr>
        <td width="25%">
          <img src='Images/weakly_supervised_cnn.JPG' width="280" height="250">
        </td>
        <td valign="top" width="75%">
          <p>
            <a href="https://doi.org/10.1142/9789811223334_0084">
              <papertitle>Weakly-supervised Character-level Convolutional Neural Networks for Text Classification</papertitle>
            </a>
            <br>
            <a href="">Yongsheng Liu</a>,
            <a href="https://en.uestc.edu.cn/info/1074/2672.htm">Wenyu Chen</a>,
            <strong>Rubungo Andre Niyongabo</strong>
            <a href="https://en.uestc.edu.cn/info/1074/2124.htm">Hong Qu</a>
            <br>
            <em> In Proceedings of the 14th International FLINS Conference (FLINS 2020), World Scientific.</em>
            <br>
            <a href="https://doi.org/10.1142/9789811223334_0084">Paper</a>
          </p>
          <p>Text classification is a fundamental task in Natural Language Processing (NLP). In this paper, we propose a Weakly-Supervised Character-level Convolutional Network (WSCCN) for text classification. Compared to the word-based model, WSCCN extracting information from raw signals. Further, through the combination of global pooling and fully convolutional networks, our model retains semantic position information from stem to stern. Extensive experiments on the most widely-used seven large-scale datasets show that WSCCN could not only achieve state-of-the-art or competitive classification results but show critical parts of the text for classification.</p>
        </td>
      </tr>
      <tr>
        <td width="25%">
          <img src='Images/emotion_bert.JPG' width="280" height="250">
        </td>
        <td valign="top" width="75%">
          <p>
            <a href="https://ieeexplore.ieee.org/abstract/document/9317523">
              <papertitle>Recognizing Emotions from Texts using a Bert-Based Approach</papertitle>
            </a>
            <br>
            <a href="https://scholar.google.com/citations?user=tjkFrN4AAAAJ&hl=en">Francisca A. Acheampong</a>,
            <a href="">Henry Nunoo-Mensah</a>,
            <a href="https://en.uestc.edu.cn/info/1074/2672.htm">Wenyu Chen</a>,
            <strong>Rubungo Andre Niyongabo</strong>
            <br>
            <em> In 2020 17th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP) (pp. 62-66). IEEE.</em>
            <br>
            <a href="https://ieeexplore.ieee.org/abstract/document/9317523">Paper</a>
          </p>
          <p>The popularity of using pre-trained models results from the training ease and superior accuracy achieved in relatively shorter periods. The paper analyses the efficacy of utilizing transformer encoders on the ISEAR dataset for detecting emotions (i.e., anger, disgust, sadness, fear, joy, shame, and guilt). This work proposes a two-stage architecture. The first stage has the Bidirectional Encoder Representations from Transformers (BERT) model, which outputs into the second stage consisting of a Bi-LSTM classifier for predicting their emotion classes accordingly. The results, outperforming that of the state-of-the-art, with a higher weighted average F1 score of 0.73, become the new state-of-the-art in detecting emotions on the ISEAR dataset.</p>
        </td>
      </tr>
      
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="25">
      <tr>
        <td>
          <heading>Teaching</heading>
          /
          <p> I have been a teaching assistant (TA)/tutor for the following courses/tutorial/workshops at  University of Electronic Science and Technology of China (UESTC).</p>
        </td>
      </tr>
      </table>

      <table width="100%" align="center" border="0" cellpadding="25">
      <tr>
        <td width="25%"><img src="Images/uestc_logo.jfif" alt="pacman" width="180" height="180"></td>
        <td width="75%" valign="right">
          <p>
            <papertitle>TA for Graduate Comprehensive Chinese Course - Fall 2020</papertitle>
            <br><br>
            <papertitle>TA and co-organizer of the 1st and 2nd UESTC Deep Learning Workshops  - Fall 2018 and Spring 2019</papertitle>
            <br><br>
            <papertitle>Tutor for UESTC CS Web Development Tutorial - Fall 2017 and Spring 2018</papertitle>
            <br>
          </p>
        </td>
      </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Leadership</heading>
          <p> I am fortunate that I have served in the following positions while at UESTC. </p>
          <ul style="list-style-type:circle">
            <li class="some_list"> Sep 2020 - Jul 2021: Academic Committee Member of International Student Union (ISU) and Country Representative of Rwandan students.</li>
            <li class="some_list"> Sep 2017 - Jul 2018: Academic Officer in charge of Undergraduate Students for ISU.</li>
            <li class="some_list"> Sep 2015 - Jul 2017: Representative of International Students in Chinese and Overseas Student Association (COSA).</li>
          </ul>         
        </td>
      </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Awards and Honors</heading>
          <!-- <p>I am fortunate that I have served in the following positions while at UESTC.</p> -->
          <ul style="list-style-type:circle">
            <li class="some_list"> 2021: Best Paper Award at EACL 2021, AfricaNLP Workshop, Wikimedia Foundation Research Award of the Year, and Chinese Government Outstanding International Masters Student Award.</li>
            <li class="some_list"> 2020: UESTC Outstanding Masters Student Award and 1st prize of Academic Achievement Award.</li>
            <li class="some_list"> 2018: UESTC Outstanding Undergraduate Student Award.</li>
            <li class="some_list"> 2017: 1st prize of Academic Achievement Award and 1st prize of Excellent Performance Award.</li>
            <li class="some_list"> 2016: 1st prize of Academic Achievement Award. &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;</li>
            <li class="some_list"> 2015: 1st prize of Chinese Language Studies Award.</li>
          </ul>         
        </td>
      </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Languages</heading>
          <!-- <p>I am fortunate that I have served in the following positions while at UESTC.</p> -->
          <ul style="list-style-type:circle">
            <li class="some_list"> Strong reading, writing, speaking and listening competencies for <strong>English</strong>, <strong>Mandarin Chinese</strong>, and <strong>Kinyarwanda</strong>.</li>
            <li class="some_list"> Moderate reading, writing, speaking and listening competencies for <strong>French</strong> and <strong>Kirundi</strong>.&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;</li>
            <li class="some_list"> Beginner in <strong>Spanish</strong>.</li>
          </ul>         
        </td>
      </tr>
      </table>

    </td>
    </tr>
  </table>
  </body>
</html>
