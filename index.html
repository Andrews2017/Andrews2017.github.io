<!-- Page adopted from https://github.com/adjidieng/adjidieng.github.io and https://github.com/jonbarron/website -->

<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    a {
      color: #1772d0;
      text-decoration:none;
    }

    em {
      color: #1772d0;
    }

    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }

    td,th,tr,p,a {
      font-family:  'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 17px;
      font-weight: 300;
    }

    body { 
    	margin:5px 0; 
    	padding:0; 
    	font-size: 100%;
    	font-family: "PT Serif","Georgia","Helvetica Neue",Arial,sans-serif; 
    	color:#FFF;  
    	background-color:#eee;
    	line-height: 1.4em; 
    	/*background : #E4E4E4 url(bg.gif) repeat-x;*/
     	/*background: #E4E4E4 url(bg_light.gif) repeat-x; */
    	background: #FFFFFF url(bc-website-color.gif) repeat-x;
    }
    p { 
    	margin: 0 0 5px 0; 
    	padding: 0; 
    	color: #404241; 
    	background: inherit;
    	font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 95%;
      font-weight: 400;
    }

    hr {
      border: 0;
      height: 1px;
      color: #eee;
      background-color: #eee;
    }

    a { 
    	background: inherit; 
    	text-decoration:none;
    	font-size:95%;
      color: #191970;

    }

    a:hover { 
    	background: inherit;
    	text-decoration: none;

    }

    h1 { 
    	padding:0; 
    	margin:0; 
    	color: #434A55; 
    	background: inherit;
    	font-family: serif; 
    	/*font-size: 22px;*/
    	/*letter-spacing: 0px;*/
    }

    h1 a {
    	color: #191970; 
    	background: inherit;
    }

    h2 { 
    	background-color: inherit; 
    	color:#191970; 
    	margin: 10px 20px 10px 0px; 
    	padding:15px 0px 0 0px; 
    	font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 18px;
      font-weight: 500;

    }

    h2 a { 
    	/*background-color:#08152E;*/ 
    	/*background-color:#E4E4E4;*/
    	background-color:#FFFFFF;
    }

    ul { 	margin: 0 0 20px 0; 
    	padding : 0; 
    	list-style : none; 
      color: #555;
    }
    	
    li { 
    	float: left;
    	font-weight: bold;
    	margin: 10px 0 8px 0;
    	padding: 0 0 0 5px;
    	font-size: 95%%;
    	font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    	font-weight: 400;
      color: #404241;

    }

    li a { 
      font-size: 95%;
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-weight: 400;
      color: #191970; }
    li a:hover {text-decoration: none; 
      background: inherit url(select.gif) no-repeat center top;padding: 2px 4px;
    	background-position: 100% 100%;
      color: #DBBC58;
      padding: 4px 8px; 
      background-color:#191970; 
      border-radius: 25px;
      display: run-in;
    }

    strong {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 15px;
      color: #191970;
    }

    heading {
      font-family:  'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 23px;
      color: #191970;
    }

    papertitle {
      font-family:  'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 17px;
      font-weight: 700
    }

    name {
      font-family:  "PT Serif","Georgia","Helvetica Neue",Arial,sans-serif; 
      font-size: 35px;
      font-weight: bold;
    }
    
    span.highlight {
      background-color: #ffffd0;
    }

    .some_list { 
    	font-size: 93%;
    	font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
    	font-weight: 400;
    	/*float: none;*/
    	list-style-type: circle;
    	padding : 0px; 
    	margin: 0 0 10px 30px; 
      }
  </style>
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="Images/profile_pic.png">
  <title>Rubungo Andre Niyongabo </title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Roboto:300,400,500,700,900,100italic,100,300,300italic,400italic,500italic,900italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <table width="70%" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
          <p>
            <name>Rubungo Andre Niyongabo</name>
          </p>
          <p>
            <img src="Images/profile_pic.png" width="30%">
          </p>
          <p>
            <a href=" ">CV</a> &nbsp/&nbsp
            <a href="https://scholar.google.com/citations?user=5qnTWQEAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
            <a href="https://www.linkedin.com/in/rubungo-andre-niyongabo-851370168/"> LinkedIn </a> &nbsp/&nbsp
            <a href="https://github.com/Andrews2017">Github</a> &nbsp/&nbsp
            <a href="https://twitter.com/andre_niyongabo">Twitter</a>  &nbsp/&nbsp
            <a> Email:</a>  niyongabo dot rubungo dot andre at upc dot edu 
          </p>
        </td>
      </tr>
      </table> -->
  
      <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <p>I am a Research Assistant in the department of <a href="https://www.cs.upc.edu/">Computer Science</a>
          at <a href="https://www.upc.edu/en">Polytechnic University of Catalonia (UPC)</a> where I am jointly working with <a href="https://costa-jussa.com/">Prof. Marta R. Costa-jussà</a>
          and  <a href="https://www.talp.upc.edu/staff-detail-page-2/61/Carlos-Escolano%20Peinado">Carlos Escolano</a> on <a href="https://lunar.cs.upc.edu/">LUNAR</a> project. In my research, I work on improving Neural Machine Translation systems for Extremely Low Resource Languages, especially African languages. My work is funded by the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme. 
          </p>

          <p> &nbsp </p>
          <p>
           Prior to joining UPC I did my masters and undergraduate in Computer Science in China at <a href="https://en.uestc.edu.cn/">University of Electronic Science and Technology of China (UESTC)</a>. During my masters, I did internships at <a href="https://www.huawei.com/en/corporate-information/research-development">Huawei</a> and <a href="https://online.iwhalecloud.com/">WhaleCloud</a> as an Artificial Intelligence (AI) Engineer. While at UESTC, I have received several awards including <a href="Awards/chinese_government_award_2021.pdf">Chinese Government Outstanding International Masters Student Award</a>, <a href="Awards/uestc_outstanding_masters_stud_award_2021.pdf">UESTC Outstanding Masters Student Award</a>, and <a href="Awards/uestc_undergraduate_outstanding_stud_award.pdf">UESTC Outstanding Undergraduate Student Award</a>.
          </p>
        </td> 
      </tr>
      </table> -->

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Rubungo Andre Niyongabo</name>
              </p>
              <p>I am a Research Assistant in the department of <a href="https://www.cs.upc.edu/">Computer Science</a>
              at <a href="https://www.upc.edu/en">Polytechnic University of Catalonia (UPC)</a> where I am jointly working with <a href="https://costa-jussa.com/">Prof. Marta R. Costa-jussà</a>
              and  <a href="https://www.talp.upc.edu/staff-detail-page-2/61/Carlos-Escolano%20Peinado">Carlos Escolano</a> on <a href="https://lunar.cs.upc.edu/">LUNAR</a> project.
              </p>
              <br> 
              <p>In my research, I work on improving Neural Machine Translation systems for Extremely Low Resource Languages, especially African languages. My work is funded by the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme. 
              </p>
              <br>
              <p>
              Prior to joining UPC I did my masters and undergraduate in Computer Science in China at <a href="https://en.uestc.edu.cn/">University of Electronic Science and Technology of China (UESTC)</a>. During my masters, I did internships at <a href="https://www.huawei.com/en/corporate-information/research-development">Huawei</a> and <a href="https://online.iwhalecloud.com/">WhaleCloud</a> as an Artificial Intelligence (AI) Engineer. While at UESTC, I have received several awards including <a href="Awards/chinese_government_award_2021.pdf">China Government Outstanding International Masters Student Award</a>, <a href="Awards/uestc_outstanding_masters_stud_award_2021.pdf">UESTC Outstanding Masters Student Award</a>, and <a href="Awards/uestc_undergraduate_outstanding_stud_award.pdf">UESTC Outstanding Undergraduate Student Award</a>.
              </p>
              <br>
              <p style="text-align:center">
                <a href=" ">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=5qnTWQEAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/rubungo-andre-niyongabo-851370168/"> LinkedIn </a> &nbsp/&nbsp
                <a href="https://github.com/Andrews2017">Github</a> &nbsp/&nbsp
                <a href="https://twitter.com/andre_niyongabo">Twitter</a>  &nbsp/&nbsp
                <a> Email:</a>  niyongabo dot rubungo dot andre at upc dot edu 
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="Images/profile_pic_circula.png"><img style="width:100%;max-width:100%" alt="profile photo" src="Images/profile_pic_circula.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody>
      </table>
 
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>News</heading>
          <ul style="list-style-type:circle">
            <li class="some_list"> Nov 2021: Started reviewing for <a href="https://iclr.cc/">ICLR 2022</a>.</li>
            <li class="some_list">Oct 2021: Starting a Research Assistant position in Computer Science departemet at <a href="https://www.upc.edu/en">UPC</a></li>
            <li class="some_list"> Jul 2021: Starting a Research and Development Internship at <a href="https://www.huawei.com/en/corporate-information/research-development">Huawei</a></li>
            <li class="some_list"> Jul 2021: Received a master's degree from <a href="https://en.uestc.edu.cn/"></a>UESTC</li>
            <li class="some_list"> Feb 2021: Received <a href="Awards/chinese_government_award_2021.pdf">China Government Outstanding International Masters Student Award</a>.</li>
            <li class="some_list"> Dec 2020: Received <a href="Awards/uestc_outstanding_masters_stud_award_2021.pdf">UESTC Outstanding Masters Student Award</a>.</li>
            <li class="some_list">Paper accepted at <a href="https://coling2020.org/">COLING 2020</a> titled "KINNEWS and KIRNEWS: Benchmarking Cross-Lingual Text Classification for Kinyarwanda and Kirundi".</li>
            <li class="some_list">Paper accepted at <a href="https://2020.emnlp.org/">EMNLP-Findings 2020</a> titled "Participatory Research for Low-resourced Machine Translation: A Case Study in African Languages".</li>
            <li class="some_list">Paper accepted at <a href="https://www.hrm-bildung.de/flins2020/">FLINS 2020</a> titled "Weakly-supervised Character-level Convolutional Neural Networks for Text Classification".</li>
            <li class="some_list">Awarded China Government Full Scholarship for Masters.</li>
            <li class="some_list">Awarded 2018 UESTC Outstanding Student Award.</li>
          </ul>         
        </td>
      </tr>
      </table>

      <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading> Selected Invited Talks </heading>
          <ul  style="list-style-type:circle">
            <li class="some_list"><a href="https://www.cs.cmu.edu/calendar/tue-2019-11-26-1030/machine-learningduolingo-seminar">Carnegie Mellon University Machine Learning Seminar</a>, Pittsburgh, PA, November 2019 </li>
            <li class="some_list"> Add more here...</li>  
          </ul>         
        </td>
      </tr>
      </table> -->

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Research</heading>
          <p> My main goal as a Natural Language Processing (NLP) researcher is to increase the representation of low resource languages, especially African languages in an NLP community. My previous works range from the creation and curation of new datasets, machine translation, text classification, text summarization, sentiment analysis, named-entity recognition, and common sense reasoning. 
          </p>
        </td>
      </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="25">
      <!-- <tr>
        <td width="25%">
          <img src='Figures/kinyaBERTModel.pdf' width="280" height="250">
        </td>
        <td valign="top" width="75%">
          <p>
            <a href="https://openreview.net/forum?id=AunN5vQYjsB">
              <papertitle>KinyaBERT: A Morphology-aware Kinyarwanda Language Model</papertitle>
            </a>
            <br>
            <a href="https://www.linkedin.com/antoine-nzeyimana-23b302112">Antoine Nzeyimana</a>,
            <strong>Rubungo Andre Niyongabo</strong>
            <br>
            <em> Under review</em>
            <br>
            <a href="https://doi.org/10.1162/tacl_a_00416">Paper</a>
            /
            <a href="https://gem-benchmark.com/">Video</a>
            / 
            <a href="https://gem-benchmark.com/team">Poster</a>
          </p>
          <p>GEM is a benchmark environment for Natural Language Generation with a focus on its Evaluation, both through human annotations and automated Metrics. It aims to measure NLG progress across many NLG tasks across languages, audit data and models and present results via data cards and model robustness reports, and develop standards for evaluation of generated text using both automated and human metrics.</p>
        </td>
      </tr> -->
      <tr>
        <td width="25%">
          <img src='Images/gem_1.JPG' width="280" height="250">
        </td>
        <td valign="top" width="75%">
          <p>
            <a href="Papers/GEM_Benchmark_1.pdf">
              <papertitle>The GEM Benchmark: Natural Language Generation, its Evaluation and Metrics</papertitle>
            </a>
            <br>
            <a href="https://sebastiangehrmann.com/">Sebastian Gehrmann</a>,
            <a href="https://scholar.google.com/citations?user=uBZIR8sAAAAJ&hl=en">Tosin Adewumi</a>,
            <span>et al. including</span>
            <strong>Rubungo Andre Niyongabo</strong>
            <br>
            <em> In the Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021), pages 96–120</em>
            <br>
            <a href="https://aclanthology.org/2021.gem-1.10/">Paper</a>
            /
            <a href="https://gem-benchmark.com/">Website</a>
            / 
            <a href="https://gem-benchmark.com/team">Team</a>
          </p>
          <p>GEM is a benchmark environment for Natural Language Generation with a focus on its Evaluation, both through human annotations and automated Metrics. It aims to measure NLG progress across many NLG tasks across languages, audit data and models and present results via data cards and model robustness reports, and develop standards for evaluation of generated text using both automated and human metrics.</p>
        </td>
      </tr>
      <tr>
        <td width="25%">
          <img src='Images/mpt.png' width="280" height="250">
        </td>
        <td valign="top" width="75%">
          <p>
            <a href="https://dl.acm.org/doi/abs/10.1145/3457682.3457759">
              <papertitle>Multi-Perspective Reasoning Transformers</papertitle>
            </a>
            <br>
            <a href="https://www.linkedin.com/in/dagisky/">Dagmawi Moges</a>,
            <strong>Rubungo Andre Niyongabo</strong>,
            <a href="https://en.uestc.edu.cn/info/1074/2124.htm">Hong Qu</a>
            <br>
            <em>In 2021 13th International Conference on Machine Learning and Computing (ICMLC 2021)</em>
            <br>
            <a href="https://dl.acm.org/doi/abs/10.1145/3457682.3457759">Paper</a>
          </p>
          <p>Machine Reading Comprehension is defined as the ability of machines to read and understand unstructured text and answer questions about it. It is considered as a challenging task with wide range of enterprise applications. Wide range of natural language understanding and reasoning tasks are found embedded within machine reading comprehension datasets. This requires effective models with robust relational reasoning capabilities to answer complex questions. Reasoning in natural language is a long-term machine-learning goal and is critically needed for building intelligent agents. However, most papers heavily depend on underlying language modeling and thus pay little to no attention on creating effective reasoning models. This paper proposes a modified transformer architecture that effectively combines soft and hard attention to create multi-perspective reasoning model capable of tackling wide range of reasoning tasks. An attention mechanism that highlights the relational significance of input signals is considered as well. The result from this study shows performance gain as compared to its counterpart the transformer network on bAbI dataset, a natural language reasoning tasks.</p>
        </td>
      </tr>
      <tr>
        <td width="25%">
          <img src='Images/masakhaner.JPG' width="280" height="250">
        </td>
        <td valign="top" width="75%">
          <p>
            <a href="https://doi.org/10.1162/tacl_a_00416">
              <papertitle>MasakhaNER: Named Entity Recognition for African Languages.</papertitle>
            </a>
            <br>
            <a href="">David I. Adelani</a>,
            <a href="">Jade Abbott</a>,
            <span>et al. including</span>
            <strong>Rubungo Andre Niyongabo</strong>
            <br>
            <em> Transactions of the Association for Computational Linguistics (2021).</em>
            <br>
            <a href="https://doi.org/10.1162/tacl_a_00416">Paper</a>
            /
            <a href="">Video</a>
            / 
            <a href="">Poster</a>
          </p>
          <p>We take a step towards addressing the under- representation of the African continent in NLP research by bringing together different stakeholders to create the first large, publicly available, high-quality dataset for named entity recognition (NER) in ten African languages. We detail the characteristics of these languages to help researchers and practitioners better understand the challenges they pose for NER tasks. We analyze our datasets and conduct an extensive empirical evaluation of state- of-the-art methods across both supervised and transfer learning settings.</p>
        </td>
      </tr>
      <tr>
        <td width="25%">
          <img src='Figures/quality_at_glance.pdf' width="280" height="250">
        </td>
        <td valign="top" width="75%">
          <p>
            <a href="https://doi.org/10.1162/tacl_a_00447">
              <papertitle>Quality at a Glance: An Audit of Web-Crawled Multilingual Datasets.</papertitle>
            </a>
            <br>
            <a href="">Isaac Caswel</a>,
            <a href="">Julia Kreutzer</a>,
            <span>et al. including</span>
            <strong>Rubungo Andre Niyongabo</strong>
            <br>
            <em> Transactions of the Association for Computational Linguistics (2021).</em>
            <br>
            <a href="https://doi.org/10.1162/tacl_a_00447">Paper</a>
            /
            <a href="">Video</a>
            / 
            <a href="">Poster</a>
          </p>
          <p>With the success of large-scale pre-training and multilingual modeling in Natural Language Processing (NLP), recent years have seen a proliferation of large, Web-mined text datasets covering hundreds of languages. We manually audit the quality of 205 language-specific corpora released with five major public datasets (CCAligned, ParaCrawl, WikiMatrix, OSCAR, mC4). Lower-resource corpora have systematic issues: At least 15 corpora have no usable text, and a significant fraction contains less than 50% sentences of acceptable quality. In addition, many are mislabeled or use nonstandard/ambiguous language codes. We demonstrate that these issues are easy to detect even for non-proficient speakers, and supplement the human audit with automatic analyses. Finally, we recommend techniques to evaluate and improve multilingual corpora and discuss potential risks that come with low-quality data releases.</p>
        </td>
      </tr>
      <tr>
        <td width="25%">
          <img src='Images/kinnews_kirnews.JPG' width="280" height="250">
        </td>
        <td valign="top" width="75%">
          <p>
            <a href="https://www.aclweb.org/anthology/2020.coling-main.480/">
              <papertitle>KINNEWS and KIRNEWS: Benchmarking Cross-Lingual Text Classification for Kinyarwanda and Kirundi</papertitle>
            </a>
            <br>
            <strong>Rubungo Andre Niyongabo</strong>,
            <a href="https://en.uestc.edu.cn/info/1074/2124.htm">Hong Qu</a>,
            <a href="">Julia Kreutzer</a>,
            <a href="">Li Huang</a>
            <br>
            <em> COLING 2020.</em>
            <br>
            <a href="Papers/kinnews_kirnews.pdf">Paper</a>
          </p>
          <p>Recent progress in text classification has been focused on high-resource languages such as English and Chinese. For low-resource languages, amongst them most African languages, the lack of well-annotated data and effective preprocessing, is hindering the progress and the transfer of successful methods. In this paper, we introduce two news datasets (KINNEWS and IRNEWS) for multi-class classification of news articles in Kinyarwanda and Kirundi, two low-resource African languages. The two languages are mutually intelligible, but while Kinyarwanda has been studied in Natural Language Processing (NLP) to some extent, this work constitutes the first study on Kirundi. Along with the datasets, we provide statistics, guidelines for preprocessing, and monolingual and cross-lingual baseline models. Our experiments show that training embeddings on the relatively higher-resourced Kinyarwanda yields successful cross-lingual transfer to Kirundi. In addition, the design of the created datasets allows for a wider use in NLP beyond text classification in future studies, such as representation learning, cross-lingual learning with more distant languages, or as base for new annotations for tasks such as parsing, POS tagging, and NER.</p>
        </td>
      </tr>
      <tr>
        <td width="25%">
          <img src='Images/participatory_research.JPG' width="280" height="250">
        </td>
        <td valign="top" width="75%">
          <p>
            <a href="https://www.aclweb.org/anthology/2020.findings-emnlp.195/">
              <papertitle>Participatory Research for Low-resourced Machine Translation: A Case Study in African Languages</papertitle>
            </a>
            <br>
            <span>∀</span>,
            <a href="">Wilhelmina Nekoto</a>,
            <a href="">Vukosi Marivate</a>,
            <span>et al. including</span>
            <strong>Rubungo Andre Niyongabo</strong>
            <br>
            <em> (EMNLP-Findings 2020. ∀:Equal contribution</em>
            <br>
            <a href="n) https://www.aclweb.org/anthology/2020.findings-emnlp.195">Paper</a>
            /
            <a href="">Video</a>
            / 
            <a href="">Code</a>
          </p>
          <p>Research in NLP lacks geographic diversity, and the question of how NLP can be scaled to low-resourced languages has not yet been adequately solved. ‘Low-resourced’-ness is a complex problem going beyond data availability and reflects systemic problems in society. In this paper, we focus on the task of Machine Translation (MT), that plays a crucial role for information accessibility and communication worldwide. Despite immense improvements in MT over the past decade, MT is centered around a few high-resourced languages. As MT researchers cannot solve the problem of low-resourcedness alone, we propose participatory research as a means to involve all necessary agents required in the MT development process. We demonstrate the feasibility and scalability of participatory research with a case study on MT for African languages. Its implementation leads to a collection of novel translation datasets, MT benchmarks for over 30 languages, with human evaluations for a third of them, and enables participants without formal training to make a unique scientific contribution.</p>
        </td>
      </tr>
      <tr>
        <td width="25%">
          <img src='Images/weekly_supervised_cnn.JPG' width="280" height="250">
        </td>
        <td valign="top" width="75%">
          <p>
            <a href="https://doi.org/10.1142/9789811223334_0084">
              <papertitle>Weakly-supervised Character-level Convolutional Neural Networks for Text Classification</papertitle>
            </a>
            <br>
            <a href="">Yongsheng Liu</a>,
            <a href="">Wenyu Chen</a>,
            <strong>Rubungo Andre Niyongabo</strong>
            <a href="https://en.uestc.edu.cn/info/1074/2124.htm">Hong Qu</a>
            <br>
            <em> In Proceedings of the 14th International FLINS Conference (FLINS 2020), World Scientific.</em>
            <br>
            <a href="https://doi.org/10.1142/9789811223334_0084">Paper</a>
          </p>
          <p>Text classification is a fundamental task in Natural Language Processing (NLP). In this paper, we propose a Weakly-Supervised Character-level Convolutional Network (WSCCN) for text classification. Compared to the word-based model, WSCCN extracting information from raw signals. Further, through the combination of global pooling and fully convolutional networks, our model retains semantic position information from stem to stern. Extensive experiments on the most widely-used seven large-scale datasets show that WSCCN could not only achieve state-of-the-art or competitive classification results but show critical parts of the text for classification.</p>
        </td>
      </tr>
      <tr>
        <td width="25%">
          <img src='Images/emotion_bert.png' width="280" height="250">
        </td>
        <td valign="top" width="75%">
          <p>
            <a href="https://ieeexplore.ieee.org/abstract/document/9317523">
              <papertitle>Recognizing Emotions from Texts using a Bert-Based Approach</papertitle>
            </a>
            <br>
            <a href="">Francisca A. Acheampong</a>,
            <a href="">Henry Nunoo-Mensah</a>,
            <a href="">Wenyu Chen</a>
            <strong>Rubungo Andre Niyongabo</strong>
            <br>
            <em> In 2020 17th International Computer Conference on Wavelet Active Media Technology and Information Processing (ICCWAMTIP) (pp. 62-66). IEEE.</em>
            <br>
            <a href="https://ieeexplore.ieee.org/abstract/document/9317523">Paper</a>
          </p>
          <p>The popularity of using pre-trained models results from the training ease and superior accuracy achieved in relatively shorter periods. The paper analyses the efficacy of utilizing transformer encoders on the ISEAR dataset for detecting emotions (i.e., anger, disgust, sadness, fear, joy, shame, and guilt). This work proposes a two-stage architecture. The first stage has the Bidirectional Encoder Representations from Transformers (BERT) model, which outputs into the second stage consisting of a Bi-LSTM classifier for predicting their emotion classes accordingly. The results, outperforming that of the state-of-the-art, with a higher weighted average F1 score of 0.73, become the new state-of-the-art in detecting emotions on the ISEAR dataset.</p>
        </td>
      </tr>
      
      </table>

      <!-- <table width="100%" align="center" border="0" cellspacing="0" cellpadding="25">
      <tr>
        <td>
          <heading>Teaching</heading>
          /
          <p> I am fortunate to have been a teaching assistant for the following courses at Columbia University.</p>
        </td>
      </tr>
      </table> -->

      <!-- <table width="100%" align="center" border="0" cellpadding="25">
      <tr>
        <td width="25%"><img src="Images/teaching.jpg" alt="pacman" width="180" height="180"></td>
        <td width="75%" valign="right">
          <p>
            <papertitle>Statistical Machine Learning - Spring 2019</papertitle>
            <br><br>
            <papertitle>Advanced Data Analysis - Fall 2017</papertitle>
            <br><br>
            <papertitle>Statistical Methods for Finance - Spring 2016</papertitle>
            <br><br>
            <papertitle>Probability and Statistics for Data Science - Fall 2015</papertitle>
            <br><br>
            <papertitle>Linear Regression Models - Spring 2015</papertitle>
            <br><br>
            <papertitle>Probability - Fall 2014</papertitle>
            <br>
          </p>
        </td>
      </tr>
      </table> -->

      <!-- <table>
        Add more CV's parts here
      </table> -->

    </td>
    </tr>
  </table>
  </body>
</html>
